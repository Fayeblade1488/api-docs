---
title: Venice AI
"og:title": "Venice AI Platform - Privacy-First AI API" 
---

# The privacy-first AI platform for building uncensored applications

Build with open-source models, real privacy, uncensored capabilities, and own your inference forever.

<CardGroup cols={3}>
  <Card title="Start Building" href="/overview/getting-started" icon="rocket">
    Make your first request in minutes.
  </Card>
  <Card title="View Models" href="/overview/models" icon="database">
    Compare capabilities, context, and base models.
  </Card>
  <Card title="API Reference" href="/api-reference" icon="rectangle-code">
    Endpoints, payloads, and examples.
  </Card>
</CardGroup>

## OpenAI Compatibility

Use your existing OpenAI code with just a base URL change.

<CodeGroup>
```bash Curl
curl https://api.venice.ai/api/v1/chat/completions \
  -H "Authorization: Bearer $VENICE_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "venice-uncensored",
    "messages": [{"role": "user", "content": "Hello World!"}]
  }'
```

```ts TypeScript
import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.VENICE_API_KEY!,
  baseURL: "https://api.venice.ai/api/v1",
});

const completion = await openai.chat.completions.create({
  model: "venice-uncensored",
  messages: [{ role: "user", content: "Hello World!" }],
});

console.log(completion.choices[0].message.content);
```

```python Python
import openai

client = openai.OpenAI(
    api_key="your-api-key",
    base_url="https://api.venice.ai/api/v1"
)

response = client.chat.completions.create(
    model="venice-uncensored",
    messages=[{"role": "user", "content": "Hello World!"}]
)

print(response.choices[0].message.content)
```

```go Go
package main

import (
    "context"
    "fmt"
    "os"
    "github.com/openai/openai-go"
)

func main() {
    client, err := openai.NewClient(os.Getenv("VENICE_API_KEY"))
    if err != nil {
        fmt.Printf("Error creating client: %v\n", err)
        return
    }
    
    client.BaseURL = "https://api.venice.ai/api/v1"
    
    resp, err := client.CreateChatCompletion(
        context.Background(),
        openai.ChatCompletionRequest{
            Model: "venice-uncensored",
            Messages: []openai.ChatCompletionMessage{
                {
                    Role:    openai.ChatMessageRoleUser,
                    Content: "Hello World!",
                },
            },
        },
    )
    
    if err != nil {
        fmt.Printf("Error: %v\n", err)
        return
    }
    
    fmt.Println(resp.Choices[0].Message.Content)
}
```

```php PHP
<?php

require_once 'vendor/autoload.php';

use OpenAI\Client;

$client = OpenAI::client('your-api-key');
$client->setBaseUrl('https://api.venice.ai/api/v1');

$response = $client->chat()->create([
    'model' => 'venice-uncensored',
    'messages' => [
        [
            'role' => 'user',
            'content' => 'Hello World!'
        ]
    ]
]);

echo $response->choices[0]->message->content;
```

```csharp C#
using OpenAI;

var client = new OpenAIClient("your-api-key");
client.BaseUrl = "https://api.venice.ai/api/v1";

var chatCompletion = await client.GetChatCompletionsAsync(new ChatCompletionOptions
{
    Model = "venice-uncensored",
    Messages = { new ChatMessage(ChatRole.User, "Hello World!") }
});

Console.WriteLine(chatCompletion.Value.Choices[0].Message.Content);
```

```java Java
import com.openai.OpenAI;
import com.openai.OpenAIHttpException;
import com.openai.core.ApiError;
import com.openai.types.chat.ChatCompletionRequest;
import com.openai.types.chat.ChatCompletionResponse;
import com.openai.types.chat.ChatMessage;

public class Main {
    public static void main(String[] args) {
        OpenAI client = OpenAI.builder()
            .apiKey(System.getenv("VENICE_API_KEY"))
            .baseUrl("https://api.venice.ai/api/v1")
            .build();

        try {
            ChatCompletionResponse response = client.chatCompletions().create(
                ChatCompletionRequest.builder()
                    .model("venice-uncensored")
                    .messages(ChatMessage.of("Hello World!"))
                    .build()
            );
            
            System.out.println(response.choices().get(0).message().content());
        } catch (OpenAIHttpException e) {
            System.err.println("Error: " + e.getMessage());
        }
    }
}
```

```swift Swift
import OpenAI

let client = OpenAI(apiToken: "your-api-key")
client.baseURL = "https://api.venice.ai/api/v1"

Task {
    do {
        let response = try await client.chats.create(
            model: "venice-uncensored",
            messages: [.init(role: .user, content: "Hello World!")]
        )
        
        print(response.choices[0].message.content ?? "")
    } catch {
        print("Error: \(error)")
    }
}
```
</CodeGroup>

## Build with Venice APIs

Access chat, image generation (generate/upscale/edit), audio (TTS), and characters.

<CardGroup cols={2}>
  <Card title="Chat Completions" href="/api-reference/endpoint/chat/completions" icon="message">
    **Text + reasoning**
    
    Vision, tool use, streaming
  </Card>
  
  <Card title="Image Generation" href="/api-reference/endpoint/image/generations" icon="image">
    **Generate, upscale, and edit**
    
    Models for styles, quality, and uncensored
  </Card>
  
  <Card title="Audio Synthesis" href="/api-reference/endpoint/audio/speech" icon="headphones">
    **Text → speech**
    
    60+ multilingual voices
  </Card>
  
  <Card title="AI Characters" href="/api-reference/endpoint/characters/list" icon="user">
    **Characters API**
    
    Create, list, and chat with personas
  </Card>
</CardGroup>

[View all API endpoints →](/api-reference)

## Popular Models

Copy a Model ID and use it as `model` in your requests.

<Card title="Venice Large 1.1" icon="brain">
  Flagship model for deep reasoning and production agents.

  Model ID: `qwen3-235b`
  Base: Qwen 3 235B (Venice‑tuned)
  Context: 131k • Modalities: Text → Text

  **Use cases**
  - Agent planning and tool use
  - Complex code & system design
  - Long‑context reasoning

  ```json
  {"model":"qwen3-235b","messages":[{"role":"user","content":"Plan a zero‑downtime DB migration in 3 steps"}]}
  ```
</Card>

<CardGroup cols={2}>
  <Card title="Venice Uncensored" icon="shield">
    **Unfiltered generation**
    
    Model ID: `venice-uncensored`
    
    Base model: Venice Uncensored 1.1
    
    Context: 32k • Best for: uncensored creative, red‑team testing
    
    ```json
    {"model":"venice-uncensored","messages":[{"role":"user","content":"Give an unfiltered, blunt critique of modern content‑moderation across three major social platforms. Call out double standards, show concrete examples, and propose a radical alternative policy. No hedging."}]}
    ```
  </Card>
  
  <Card title="Venice Medium 3.1" icon="eye">
    **Vision + tools**
    
    Model ID: `mistral-31-24b`
    
    Base model: Mistral 3.1 24B
    
    Context: 131k • Supports: Vision, Function calling, image analysis
    
    ```json
    {"model":"mistral-31-24b","messages":[{"role":"user","content":"Describe this image"}]}
    ```
  </Card>
  
  <Card title="Venice Small" icon="bolt">
    **Fast and cost‑efficient**
    
    Model ID: `qwen3-4b`
    
    Base model: Qwen 3 4B
    
    Context: 40k • Best for: chatbots, classification, light reasoning
    
    ```json
    {"model":"qwen3-4b","messages":[{"role":"user","content":"Summarize:"}]}
    ```
  </Card>
  
  <Card title="Venice SD35" icon="image">
    **Image generation**
    
    Model ID: `venice-sd35`
    
    Base model: SD3.5 Large

    
    Best for: Text‑to‑image, photorealism, product shots, light upscaling
    
    ```json
    {"model":"venice-sd35","prompt":"a serene canal in venice at sunset"}
    ```
  </Card>
</CardGroup>

[View all models →](/overview/models)

## Extend models with built‑in tools

Toggle on compatible models using `venice_parameters` or model suffixes

<CardGroup cols={4}>
  <Card title="Web Search" icon="globe">
    **Real‑time web results**
  </Card>
  
  <Card title="Reasoning Mode" icon="brain">
    **Advanced reasoning**
  </Card>
  
  <Card title="Vision Processing" icon="eye">
    **Image understanding**
  </Card>
  
  <Card title="Function Calling" icon="link">
    **Tool use / APIs**
  </Card>
</CardGroup>

[View model suffixes →](/api-reference/endpoint/chat/model_feature_suffix)


## Pricing Options

<CardGroup cols={3}>
  <Card title="Pro subscription" href="/overview/pricing" icon="star">
    **$10 in free credits**
    
    One‑time credit when you upgrade
    
    Great for testing and small apps
  </Card>

  <Card title="Stake VVV (Diem)" href="https://venice.ai/token" icon="coins">
    **Own your compute**
    
    Daily allocation + staking rewards
    
    Permanent access
  </Card>

  <Card title="Pay-as-you-go (USD)" href="/overview/pricing" icon="credit-card">
    **USD payments**
    
    Fund your account in USD and pay per usage
    
    Access paid tier rate limits
  </Card>
</CardGroup>

## Start building today

Get your API key and make your first request.

<CardGroup cols={2}>
  <Card title="Getting Started" href="/overview/getting-started" icon="rocket">
    Step-by-step guide to your first API call
  </Card>

  <Card title="API Reference" href="/api-reference" icon="rectangle-code">
    Complete API documentation and endpoints
  </Card>
  
  <Card title="Postman Collection" href="/overview/guides/postman" icon="play">
    Ready-to-use API examples and testing
  </Card>
  
  <Card title="AI Agents" href="/overview/guides/ai-agents" icon="robot">
    Build with Eliza and other agent frameworks
  </Card>
</CardGroup>

<Warning>
  Venice's API is rapidly evolving. Join our [Discord](https://discord.gg/askvenice) to provide feedback and request new features. Your input shapes our development roadmap.
</Warning>

---

These docs are open source and can be contributed to on [Github](https://github.com/veniceai/api-docs). For additional guidance, see our blog post: ["How to use Venice API"](https://venice.ai/blog/how-to-use-venice-api)


